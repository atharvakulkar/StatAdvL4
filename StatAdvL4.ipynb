{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c648f09-0e8a-496b-a58f-689b367e47b2",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f611211b-fbcc-4db8-9fb3-071e2a97a136",
   "metadata": {},
   "source": [
    "ANOVA (Analysis of Variance) is a statistical test used to determine whether there are any significant differences between means of two or more groups. The basic assumptions of ANOVA are as follows:\n",
    "\n",
    "Normality: The data should be normally distributed within each group.\n",
    "\n",
    "Homogeneity of variance: The variance of the data in each group should be approximately equal.\n",
    "\n",
    "Independence: The observations in each group should be independent of each other.\n",
    "\n",
    "If any of these assumptions are violated, the results of the ANOVA may not be valid. Here are some examples of violations that could impact the validity of the results:\n",
    "\n",
    "Non-normality: If the data in any of the groups is not normally distributed, this can affect the validity of the ANOVA results. For example, if the data in one group is skewed, the mean of that group may not be a good representation of the data.\n",
    "\n",
    "Heterogeneity of variance: If the variance of the data in each group is significantly different, this can affect the validity of the ANOVA results. For example, if one group has a much larger variance than the other groups, this can make it more difficult to detect differences between means.\n",
    "\n",
    "Dependence: If the observations in any of the groups are not independent, this can affect the validity of the ANOVA results. For example, if the observations in one group are paired (e.g., before and after measurements), this violates the independence assumption and can lead to spurious results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec340d42-3af8-422e-a4cf-5267ac6d4dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0aa6113-5754-41fc-aea9-8dd7b3365627",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f486114d-6015-43ac-932e-65531839306b",
   "metadata": {},
   "source": [
    "There are three types of ANOVA:\n",
    "\n",
    "One-way ANOVA: This type of ANOVA is used when there is only one independent variable, which has three or more levels (or groups). One-way ANOVA is used to determine if there are any significant differences between the means of the different levels/groups. For example, one-way ANOVA can be used to compare the average weight loss among three different diet groups.\n",
    "\n",
    "Two-way ANOVA: This type of ANOVA is used when there are two independent variables, both of which have two or more levels. Two-way ANOVA is used to determine if there are any significant main effects (i.e., the effect of each independent variable on the dependent variable) and/or interaction effects (i.e., the combined effect of the two independent variables on the dependent variable). For example, two-way ANOVA can be used to compare the average sales of two different products (product A and product B) in two different regions (North and South).\n",
    "\n",
    "MANOVA (Multivariate Analysis of Variance): This type of ANOVA is used when there are two or more dependent variables (i.e., outcome variables) and one or more independent variables. MANOVA is used to determine if there are any significant differences between the means of the dependent variables across the different levels of the independent variable. For example, MANOVA can be used to compare the average scores on multiple personality traits (e.g., extroversion, agreeableness, neuroticism) between different age groups (young, middle-aged, and old)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ab5f97-150b-4f77-afd0-aaead719920c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f85b2ebc-f789-40e0-9ebd-a2626650f289",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concep"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2456abde-e456-4539-a9ab-c2377b3efece",
   "metadata": {},
   "source": [
    "Partitioning of variance in ANOVA (Analysis of Variance) refers to the process of decomposing the total variation in the data into different sources of variation. In other words, ANOVA breaks down the total variation in the dependent variable into the variation explained by the independent variable(s) and the variation that is not explained by the independent variable(s). This is important because it helps us understand how much of the variation in the dependent variable can be attributed to the independent variable(s).\n",
    "\n",
    "The partitioning of variance in ANOVA is typically represented by the following equation:\n",
    "\n",
    "Total variation = Variation explained by independent variable(s) + Variation not explained by independent variable(s)\n",
    "\n",
    "The variation explained by the independent variable(s) is referred to as the \"between-group\" variation, while the variation not explained by the independent variable(s) is referred to as the \"within-group\" variation.\n",
    "\n",
    "Understanding the partitioning of variance is important in ANOVA because it helps us determine if there is a significant difference between the means of the different groups being compared. If the variation explained by the independent variable(s) (i.e., the between-group variation) is much larger than the variation not explained by the independent variable(s) (i.e., the within-group variation), then it suggests that there is a significant difference between the means of the groups being compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e311845-881d-4b9a-a82d-02421b22a306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e8c5636-68ce-48b8-a24e-49356264ae85",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea0375ef-3f9f-4c39-bd4a-a77792a64f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST = 223.33333333333337\n",
      "SSE = 223.33333333333337\n",
      "SSR = 0.0\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# create three sample groups\n",
    "group1 = [10, 12, 14, 16, 18]\n",
    "group2 = [8, 11, 14, 17, 20]\n",
    "group3 = [9, 12, 15, 18, 21]\n",
    "\n",
    "# concatenate the groups\n",
    "data = group1 + group2 + group3\n",
    "\n",
    "# calculate the mean of the data\n",
    "mean = sum(data) / len(data)\n",
    "\n",
    "# calculate the total sum of squares (SST)\n",
    "SST = sum([(x - mean)**2 for x in data])\n",
    "\n",
    "# calculate the sum of squares between (SSB)\n",
    "SSB = len(group1) * (sum([(x - mean)**2 for x in group1]) / len(group1))\n",
    "SSB += len(group2) * (sum([(x - mean)**2 for x in group2]) / len(group2))\n",
    "SSB += len(group3) * (sum([(x - mean)**2 for x in group3]) / len(group3))\n",
    "\n",
    "# calculate the explained sum of squares (SSE)\n",
    "SSE = SSB\n",
    "\n",
    "# calculate the residual sum of squares (SSR)\n",
    "SSR = SST - SSE\n",
    "\n",
    "print(\"SST =\", SST)\n",
    "print(\"SSE =\", SSE)\n",
    "print(\"SSR =\", SSR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a3c9a8-839c-4e04-9f59-2d15a28dde6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ac69eef-b1f3-4331-b8ab-93ef76a6358c",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430c4d3f-a1a1-40ba-b205-8e14fc3a179d",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Load data into a pandas dataframe\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('dependent_variable ~ independent_variable_1 + independent_variable_2 + independent_variable_1 * independent_variable_2', data=data).fit()\n",
    "\n",
    "# Calculate the main effects\n",
    "main_effects = sm.stats.anova_lm(model, typ=1)\n",
    "print(main_effects)\n",
    "\n",
    "# Calculate the interaction effect\n",
    "interaction_effect = sm.stats.anova_lm(model, typ=2)\n",
    "print(interaction_effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1100c09f-a594-49ed-9636-cb256c41bf6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80efaaed-d07c-40e7-8fe3-293cb8c8e252",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "76bffc46-a42a-475b-89bb-dbe92e5ec4a5",
   "metadata": {},
   "source": [
    "If we conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02, we can conclude that there is at least one significant difference between the means of the groups being compared. The F-statistic tells us the ratio of the variance between the groups to the variance within the groups. A larger F-statistic indicates a greater difference between the group means compared to the variation within the groups. The p-value tells us the probability of obtaining a result as extreme as the observed result if there were no true differences between the groups.\n",
    "\n",
    "With a p-value of 0.02, we can interpret this result as follows: if there were no true differences between the groups, we would only expect to obtain a result as extreme as an F-statistic of 5.23 or higher by chance 2% of the time. Therefore, we reject the null hypothesis (that there are no true differences between the groups) and conclude that there is sufficient evidence to suggest that at least one of the group means is different from the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27018db-a5d9-44a8-8d54-7c35c39d7926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd8d9853-a662-4f6c-a115-b80c06eddbb5",
   "metadata": {},
   "source": [
    "#Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311a56fd-6163-423c-a08b-7461748e8309",
   "metadata": {},
   "source": [
    "In a repeated measures ANOVA, missing data can be handled in several ways:\n",
    "\n",
    "Listwise deletion: This method involves excluding any cases with missing data from the analysis. This can be done using the dropna() function in pandas. While this approach is simple, it may result in a loss of statistical power if a large amount of data is missing.\n",
    "\n",
    "Mean imputation: This method involves replacing missing values with the mean of the non-missing values. This can be done using the fillna() function in pandas. While this approach is simple and easy to implement, it may underestimate the variability of the data and result in biased estimates.\n",
    "\n",
    "Last observation carried forward (LOCF): This method involves imputing missing values with the last observed value. This can be done using the fillna(method='ffill') function in pandas. While this approach is useful for data with a temporal order, it may not be appropriate for all situations and may result in biased estimates.\n",
    "\n",
    "Multiple imputation: This method involves imputing missing values multiple times using a statistical model, and then combining the results to obtain estimates and standard errors. This can be done using the fancyimpute library in Python. While this approach is more sophisticated and can produce more accurate estimates than mean imputation or LOCF, it is computationally intensive and requires careful consideration of the underlying assumptions.\n",
    "\n",
    "The potential consequences of using different methods to handle missing data in a repeated measures ANOVA include bias in the estimated means, standard errors, and effect sizes, as well as a loss of statistical power. It's important to carefully consider the underlying assumptions and potential limitations of each method and choose the approach that is most appropriate for the specific dataset and research question. Additionally, it may be beneficial to conduct sensitivity analyses to assess the robustness of the results to different methods of handling missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdceb1ec-d884-4931-9945-99c94c3ec372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8a70b83-61eb-43fc-add7-622e7accb063",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary.\n",
    "Post-hoc tests are used after ANOVA to make pairwise comparisons between groups when the overall ANOVA result is statistically significant. The purpose of post-hoc tests is to determine which specific groups differ from each other and to control for the familywise error rate, which is the probability of making at least one Type I error (false positive) across all the pairwise comparisons. Here are some common post-hoc tests used after ANOVA, along with an example of a situation where each one might be necessary:\n",
    "\n",
    "Tukey's HSD (honestly significant difference) test: This test is a conservative post-hoc test that is commonly used when the sample sizes are equal across groups. It controls for the familywise error rate by adjusting the significance level for each pairwise comparison. For example, if we have four groups (A, B, C, D), and the overall ANOVA result is significant, we might use Tukey's HSD test to determine which specific groups differ from each other. If the test shows that group A is significantly different from group B and group C, but not group D, we can conclude that group A is significantly different from groups B and C, but not group D.\n",
    "\n",
    "Bonferroni correction: This test is a simple and commonly used method to adjust the significance level for each pairwise comparison. It divides the significance level (usually 0.05) by the number of comparisons being made. For example, if we have four groups (A, B, C, D), and the overall ANOVA result is significant, we might use the Bonferroni correction to determine which specific groups differ from each other. If the test shows that group A is significantly different from group B, group C, and group D, we can conclude that group A is significantly different from all the other groups.\n",
    "\n",
    "Dunnett's test: This test is used when we have one control group and several treatment groups. It compares each treatment group to the control group, while controlling for the overall familywise error rate. For example, if we have one control group and three treatment groups (A, B, C), and the overall ANOVA result is significant, we might use Dunnett's test to determine which specific treatment groups differ from the control group. If the test shows that group A is significantly different from the control group, but groups B and C are not significantly different from the control group, we can conclude that group A is significantly different from the control group, but groups B and C are not.\n",
    "\n",
    "Scheffe's test: This test is a conservative post-hoc test that is used when the sample sizes are unequal across groups. It controls for the familywise error rate by adjusting the significance level for each pairwise comparison. For example, if we have four groups (A, B, C, D), and the overall ANOVA result is significant, we might use Scheffe's test to determine which specific groups differ from each other. If the test shows that group A is significantly different from group B and group C, but not group D, we can conclude that group A is significantly different from groups B and C, but not group D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be57a9c6-eb45-4340-8b81-d449cdbd79b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec11d6f8-7e9a-47e8-90db-07c864eb5569",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45b3c437-252e-40c8-ae97-2e191a52540b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 176.89689491604346\n",
      "p-value: 1.63227843737611e-28\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sample data\n",
    "diet_A = [4.2, 5.1, 3.7, 6.2, 4.9, 2.8, 5.4, 4.7, 3.9, 4.1,\n",
    "          3.3, 5.5, 4.8, 5.3, 3.9, 6.1, 4.3, 3.5, 5.2, 5.0,\n",
    "          5.6, 3.8, 5.8, 4.0, 5.7]\n",
    "diet_B = [2.9, 1.9, 2.5, 2.3, 3.2, 2.7, 1.8, 3.1, 2.6, 3.0,\n",
    "          2.4, 2.0, 2.8, 2.2, 2.1, 2.6, 2.7, 1.6, 2.4, 2.9,\n",
    "          3.0, 1.8, 2.1, 2.3, 2.6]\n",
    "diet_C = [1.3, 0.9, 1.1, 1.6, 1.4, 1.8, 1.2, 1.5, 2.0, 1.4,\n",
    "          1.7, 1.3, 1.9, 1.0, 1.6, 1.2, 1.8, 1.4, 1.1, 1.7,\n",
    "          1.5, 1.6, 1.9, 1.2, 1.4]\n",
    "\n",
    "# One-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Print results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d3456f-4c42-411d-8f97-bc2a77def4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84220933-3f47-4f5a-83d7-ef024265ad0d",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "raw",
   "id": "cee2e773-a99b-472d-ab08-f79d05b96de0",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "data = pd.read_csv(\"task_completion_times.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067e015a-f2e7-4915-b1ee-b663ca4e8569",
   "metadata": {},
   "source": [
    "model = ols('Time ~ C(Program) + C(Experience) + C(Program):C(Experience)', data=data).fit()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "771f9595-c0e4-48bf-80f4-5fe92b7581c6",
   "metadata": {},
   "source": [
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c49af29-b885-45cd-8940-9de84cdf08c3",
   "metadata": {},
   "source": [
    "Here, we're using the C function to indicate that Program and Experience are categorical variables, and : to indicate the interaction term between Program and Experience.\n",
    "\n",
    "We can then use the anova_lm function from the statsmodels.api module to obtain the ANOVA table and calculate the F-statistics and p-values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670ce8c8-bf55-484f-8d3c-ed8ec2a84787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "565b5b4e-ac2e-47a4-9047-81eb81fd02d5",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "raw",
   "id": "2a328087-f058-4406-84b0-4f47b957de18",
   "metadata": {},
   "source": [
    " #To conduct a two-sample t-test in Python, we first need to import the necessary packages and read in the data:\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "data = pd.read_csv(\"test_scores.csv\")\n",
    "\n",
    "#The data should be in a CSV file with two columns: \"Group\" (control or experimental) and \"Score\" (the test score).\n",
    "#We can then use the ttest_ind function from the scipy.stats module to conduct a two-sample t-test:\n",
    "\n",
    "\n",
    "control_scores = data[data[\"Group\"] == \"control\"][\"Score\"]\n",
    "experimental_scores = data[data[\"Group\"] == \"experimental\"][\"Score\"]\n",
    "t, p = ttest_ind(control_scores, experimental_scores)\n",
    "print(\"t = {:.2f}, p = {:.4f}\".format(t, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54e2b3d-a8ce-47dc-b780-efc2743bda26",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f749583-034c-4f86-b5d4-5f32a8081ef9",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store n those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post- h c test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90fab70-4b1d-44bd-93be-728ddda962c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
